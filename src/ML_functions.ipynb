{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionMetrics:\n",
    "    \"\"\" содержит y_true, y_pred. Служит для расчета метрик качества, \n",
    "    и вывода изображений: confusion_matrix, roc_auc, precision_recall\n",
    "    \"\"\"\n",
    "    def __init__(self, y_true, y_pred, y_proba = None, **kwargs):\n",
    "\n",
    "        self.y_true = y_true\n",
    "        self.y_pred = y_pred\n",
    "        self.y_proba = y_proba\n",
    "\n",
    "    def metrics(self):\n",
    "        dMetrics = dict()\n",
    "        dMetrics['rocauc'] = round(roc_auc_score(self.y_true, self.y_pred), 2)\n",
    "        dMetrics['accuracy'] = round(accuracy_score(self.y_true, self.y_pred), 2)\n",
    "        dMetrics['recall'] = round(recall_score(self.y_true, self.y_pred), 2)\n",
    "   \n",
    "        return dMetrics\n",
    "\n",
    "    def print_metrics(self):\n",
    "        print(self.metrics())\n",
    "    \n",
    "    def confusion_matrix(self, normalize=None):\n",
    "        return confusion_matrix(self.y_true, self.y_pred, normalize=normalize)\n",
    "  \n",
    "    def plot_confusion_matrix(self, normalize=None, **kwargs):\n",
    "        \n",
    "        width = kwargs.get('width', 600)\n",
    "        height = kwargs.get('height', 400)\n",
    "        classes = kwargs.get('classes', ['дефолт=0', 'дефолт=1'])\n",
    "        show = kwargs.get('show', True)\n",
    "\n",
    "        title = kwargs.get('title', 'Confusion matrix')\n",
    "        colorscale = kwargs.get('colorscale', 'Viridis')\n",
    "        \n",
    "\n",
    "        cm  = self.confusion_matrix(normalize=normalize)\n",
    "\n",
    "        fmt = '.2f' if normalize!=None else 'd'\n",
    "        z_value = 'Доля' if normalize!=None else 'Count'\n",
    "        # change each element of z to type string for annotations\n",
    "        cm_text = [[format(y, fmt)  for y in x] for x in cm]\n",
    "\n",
    "        # set up figure \n",
    "        fig = ff.create_annotated_heatmap(cm, x=classes, y=classes, annotation_text=cm_text, \n",
    "                                colorscale=colorscale, hovertemplate=\n",
    "                                            \"Real value: %{y}<br>\" +\n",
    "                                            \"Predicted value: %{x}<br>\" +\n",
    "                                            z_value + \": %{z:.2f}<br>\" +\n",
    "                                            \"<extra></extra>\",)\n",
    "\n",
    "        # add custom xaxis title\n",
    "        fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                                x=0.5,\n",
    "                                y=-0.15,\n",
    "                                showarrow=False,\n",
    "                                text=\"Predicted value\",\n",
    "                                xref=\"paper\",\n",
    "                                yref=\"paper\"))\n",
    "\n",
    "        # add custom yaxis title\n",
    "        fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                                x=-0.35,\n",
    "                                y=0.5,\n",
    "                                showarrow=False,\n",
    "                                text=\"Real value\",\n",
    "                                textangle=-90,\n",
    "                                xref=\"paper\",\n",
    "                                yref=\"paper\"))\n",
    "\n",
    "        # adjust margins to make room for yaxis title\n",
    "        fig.update_layout(margin=dict(t=50, l=150))\n",
    "        fig.update_xaxes(side=\"bottom\")\n",
    "        fig.update_layout(title_text='<i><b>'+title+'</b></i>')\n",
    "        # add colorbar\n",
    "        fig['data'][0]['showscale'] = True\n",
    "\n",
    "        fig.update_layout(autosize=False, width=width, height=height,)\n",
    "        if show:\n",
    "            fig.show('png' if need_svg else '')\n",
    "        return fig\n",
    "    \n",
    "    \n",
    "    def plot_roc_curve(self, **kwargs):\n",
    "\n",
    "        assert self.y_proba is not None, 'Не задан y_proba у PredictionMetrics'\n",
    "        \n",
    "        title = kwargs.get('title', \"\")\n",
    "        show = kwargs.get('show', True)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(self.y_true, self.y_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        GINI = (2 * roc_auc) - 1\n",
    "\n",
    "        if title:\n",
    "            title = title + '<br>'\n",
    "            \n",
    "        fig = px.area(\n",
    "            x=fpr, y=tpr,\n",
    "            title=title+f'ROC Curve (AUC={roc_auc:.4f}, GINI={GINI:.4f})',\n",
    "            labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "            width=700, height=500\n",
    "        )\n",
    "        fig.add_shape(\n",
    "            type='line', line=dict(dash='dash'),\n",
    "            x0=0, x1=1, y0=0, y1=1\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "        fig.update_xaxes(constrain='domain')\n",
    "        fig.update_layout(autosize=False, width=450, height=450,)\n",
    "        \n",
    "        if show:\n",
    "            fig.show('png' if need_svg else '')\n",
    "            \n",
    "        return fig\n",
    "\n",
    "    def plot_precision_recall(self, **kwargs):\n",
    "\n",
    "        assert self.y_proba is not None, 'Не задан y_proba у PredictionMetrics'\n",
    "        \n",
    "        title = kwargs.get('title', \"\")\n",
    "        show = kwargs.get('show', True)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(self.y_true, self.y_proba)\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(self.y_true, self.y_proba)\n",
    "\n",
    "        if title:\n",
    "            title = title + '<br>'\n",
    "\n",
    "        fig = px.area(\n",
    "                x=recall, y=precision,\n",
    "                title=title+f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n",
    "                labels=dict(x='Recall', y='Precision'),\n",
    "                width=700, height=500\n",
    "        )\n",
    "\n",
    "        fig.add_shape(\n",
    "            type='line', line=dict(dash='dash'),\n",
    "            x0=0, x1=1, y0=1, y1=0\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "        fig.update_xaxes(constrain='domain')\n",
    "        fig.update_layout(autosize=False, width=450, height=450,)\n",
    "        if show:\n",
    "            fig.show('png' if need_svg else '')\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    \"\"\" Инициализация входных данных. X_train, y_train\n",
    "        разбиение выборки на test и train, если needToSplit\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        pass \n",
    "    \n",
    "    def split_data(self, X_raw, y_raw, **kwargs):\n",
    "        test_size = kwargs.get('test_size', 0.2)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=test_size, random_state=4)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def set_scaler(self, X):\n",
    "        Scaler = StandardScaler()\n",
    "        Scaler.fit(X)\n",
    "        \n",
    "        return Scaler\n",
    "    \n",
    "    def scaling(self, X):\n",
    "        Xscaled = X.copy()\n",
    "        \n",
    "        if Xscaled.ndim == 1:\n",
    "            Xscaled = Xscaled.reshape((-1, 1))\n",
    "            \n",
    "        if self.Scaler:\n",
    "            if isinstance(Xscaled, pd.DataFrame):\n",
    "                Xscaled[Xscaled.columns] = self.Scaler.transform(Xscaled[Xscaled.columns])\n",
    "            else:\n",
    "                Xscaled = self.Scaler.transform(Xscaled)\n",
    "\n",
    "        return Xscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка, что либо X_test, y_test одновременно заданы либо одновременно не заданы\n",
    "def validate(func):\n",
    "    \n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        X_test = kwargs.get('X_test', None)\n",
    "        y_test = kwargs.get('y_test', None)\n",
    "\n",
    "        if (X_test is None) ^ (y_test is None):\n",
    "            assert False, \"\"\"варианты входных данных: \n",
    "                        1. X_raw, y_raw, X_test, y_test - заданы\n",
    "                        2. X_raw, y_raw заданы, X_test, y_test - не заданы\"\"\"\n",
    "                        \n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "class RegressionBase(ABC, Preprocessing, PredictionMetrics):\n",
    "    \n",
    "    @validate\n",
    "    def __init__(self, X_raw, y_raw, X_test=None, y_test=None, **kwargs):\n",
    "        \n",
    "        needToSplit = kwargs.get('needToSplit', True)\n",
    "        # если задан X_test - уже split не делаем\n",
    "        needToSplit = X_test is None and needToSplit\n",
    "        \n",
    "        norm = kwargs.get('norm', True)\n",
    "        self.class_weight = kwargs.get('class_weight', 'balanced')\n",
    "        \n",
    "        # это сохраним для отладки\n",
    "        self.param_add = {'needToSplit':needToSplit, 'norm':norm, 'class_weight':self.class_weight}\n",
    "        \n",
    "        if needToSplit:\n",
    "            X_train, X_test, y_train, y_test = self.split_data(X_raw, y_raw)\n",
    "        else:\n",
    "            # уже разбит на train и test. ничего не делаем\n",
    "            X_train = X_raw\n",
    "            y_train = y_raw\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test   \n",
    "        \n",
    "\n",
    "        self.Scaler = self.set_scaler(self.X_train) if norm == True else None\n",
    "        \n",
    "        self.model, self.model_not_balanced = self.set_model(**kwargs)\n",
    "\n",
    "        if X_test is not None and y_test  is not None:\n",
    "            y_pred, y_proba = self.predict(X_test)\n",
    "\n",
    "            \"\"\"  Инициализируем для PredictionMetrics \"\"\"\n",
    "            self.y_true = y_test\n",
    "            self.y_pred = y_pred\n",
    "            self.y_proba = y_proba\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_model(self,  **kwargs):\n",
    "        model = None\n",
    "        model_not_balanced = None\n",
    "        return model, model_not_balanced\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        X_standard = self.scaling(X_test)\n",
    "           \n",
    "        y_prob = self.model_not_balanced.predict_proba(X_standard)\n",
    "        y_pred = self.model.predict(X_standard)\n",
    "       \n",
    "        return y_pred, y_prob[:, 1]\n",
    "    \n",
    "    def get_coef(self):\n",
    "        coef = dict()\n",
    "        coef['intercept'] = round(self.model.intercept_[0], 4)\n",
    "        coef['coef'] = self.model.coef_[0].round(4)\n",
    "        return coef\n",
    "\n",
    "    def print_coef(self):\n",
    "        print(self.get_coef())\n",
    "        \n",
    "    def print_param(self):\n",
    "        print(\"len X_train {},  len y_train {}\".format(len(self.X_train),  len(self.y_train)))\n",
    "        if self.X_test is not None and self.y_test is not None:\n",
    "            print(\"len X_test {}, len y_test {}\".format(len(self.X_test), len(self.y_test)))\n",
    "        else:\n",
    "            print('no test data')\n",
    "            \n",
    "        print(self.param_add)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDecisionTree(RegressionBase):\n",
    "    \n",
    "    def __init__(self, X_raw, y_raw, X_test=None, y_test=None, **kwargs):\n",
    "        self.max_depth = kwargs.get('max_depth', None)\n",
    "        self.max_leaf_nodes = kwargs.get('max_leaf_nodes', None)\n",
    "        self.criterion = kwargs.get('criterion', 'gini')\n",
    "        \n",
    "        norm = kwargs.get('norm', False)\n",
    "        kwargs['norm'] = norm\n",
    "        \n",
    "        super().__init__(X_raw=X_raw, y_raw=y_raw, X_test=X_test, y_test=y_test, **kwargs)\n",
    "    \n",
    "    def set_model(self,  **kwargs):\n",
    "        X_train = self.scaling(self.X_train)\n",
    "\n",
    "        model = DecisionTreeClassifier(random_state=0, max_depth=self.max_depth, max_leaf_nodes=self.max_leaf_nodes, \n",
    "                                       class_weight=self.class_weight)\\\n",
    "                            .fit(X_train, self.y_train)\n",
    "        model_not_balanced = DecisionTreeClassifier(random_state=0, max_depth=self.max_depth, max_leaf_nodes=self.max_leaf_nodes)\\\n",
    "                            .fit(X_train, self.y_train)\n",
    "\n",
    "        return model, model_not_balanced\n",
    "    \n",
    "    def get_coef(self):\n",
    "        coef = dict()\n",
    "        coef['depth'] = self.model.get_depth()\n",
    "        coef['n_leaves'] = self.model.get_n_leaves()\n",
    "        return coef\n",
    "\n",
    "    def plot_tree(self):\n",
    "        plt.figure(figsize=(15,15))\n",
    "        _ = plot_tree(self.model, filled=True, impurity=True\n",
    "                       , feature_names = self.X_train.columns\n",
    "                    ) \n",
    "        \n",
    "        return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(RegressionBase):\n",
    " \n",
    "    def __init__(self, X_raw, y_raw, X_test=None, y_test=None, **kwargs):\n",
    "        super().__init__(X_raw=X_raw, y_raw=y_raw, X_test=X_test, y_test=y_test, **kwargs)\n",
    "    \n",
    "    def set_model(self,  **kwargs):\n",
    "        X_train = self.scaling(self.X_train)\n",
    "\n",
    "        model = LogisticRegression(solver='liblinear', class_weight=self.class_weight).fit(X_train, self.y_train)\n",
    "        model_not_balanced = LogisticRegression(solver='liblinear').fit(X_train, self.y_train)\n",
    "\n",
    "        return model, model_not_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegCV(RegressionBase):\n",
    "\n",
    "    def __init__(self, X_raw, y_raw, X_test=None, y_test=None, **kwargs):\n",
    "        super().__init__(X_raw=X_raw, y_raw=y_raw, X_test=X_test, y_test=y_test, **kwargs)\n",
    "\n",
    "    def set_model(self,  **kwargs):\n",
    "        scoring = kwargs.get('scoring', 'roc_auc')\n",
    "        X_train = self.scaling(self.X_train)\n",
    "\n",
    "        model = LogisticRegressionCV(solver='liblinear', class_weight=self.class_weight, cv=5, scoring=scoring).fit(X_train, self.y_train)\n",
    "        model_not_balanced = LogisticRegressionCV(solver='liblinear', cv=5, scoring=scoring).fit(X_train, self.y_train)\n",
    "\n",
    "        return model, model_not_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branch(PredictionMetrics):\n",
    " \n",
    "    def __init__(self, data_train, data_test, **kwargs):\n",
    "\n",
    "        X_test = data_test[['no_contracts_total', 'bad_reasons_closed']]\n",
    "        y_test = data_test['Метка дефолта']\n",
    "\n",
    "        mask = (data_train['bad_reasons_closed']>0)\n",
    "        data_branch_1 = data_train[mask]\n",
    "        \n",
    "        # data_not_bad - data_branch_2\n",
    "        data_branch_2 = data_train[~mask]\n",
    "        \n",
    "        X_raw = data_branch_2[['no_contracts_total']]\n",
    "        y_raw = data_branch_2['Метка дефолта']\n",
    "        \n",
    "        kwargs['needToSplit'] = False\n",
    "        self.log = LogRegCV(X_raw, y_raw, **kwargs)\n",
    "         \n",
    "        y_pred, y_proba = self.predict(X_test)\n",
    "        \n",
    "        self.y_true = y_test\n",
    "        self.y_pred = y_pred\n",
    "        self.y_proba = y_proba\n",
    "            \n",
    "    def predict(self, df):\n",
    "        \n",
    "        mask = (df['bad_reasons_closed']>0)\n",
    "        data_branch_1 = df[mask].copy()\n",
    "\n",
    "        # data_not_bad - data_branch_2\n",
    "        data_branch_2 = df[~mask].copy()\n",
    "\n",
    "        data_branch_1['y_prob'] = 1\n",
    "        data_branch_1['y_pred'] = 1\n",
    "\n",
    "        X_branch_2 = data_branch_2[['no_contracts_total']].copy()\n",
    "        \n",
    "        y_pred, y_prob = self.log.predict(X_branch_2)\n",
    "     \n",
    "        data_branch_2['y_prob'] = y_prob\n",
    "        data_branch_2['y_pred'] = y_pred\n",
    "\n",
    "        # соединяем результат\n",
    "        tmp = pd.merge(df, data_branch_1[['y_pred',\t'y_prob']], how='left', left_index=True, right_index=True, suffixes=['', '_br1'])\n",
    "        df_res = pd.merge(tmp, data_branch_2[['y_pred',\t'y_prob']], how='left', left_index=True, right_index=True, suffixes=['', '_br2'])\n",
    "\n",
    "        df_res['y_pred'] = df_res['y_pred'].combine_first(df_res['y_pred_br2'])\n",
    "        df_res['y_prob'] = df_res['y_prob'].combine_first(df_res['y_prob_br2'])\n",
    "        \n",
    "        return df_res['y_pred'], df_res['y_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect and remove outliers using IQR method\n",
    "def remove_outliers_iqr(data, threshold=1.5):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    filtered_data = data[~((data < (Q1 - threshold * IQR)) | (data > (Q3 + threshold * IQR))).any(axis=1)]\n",
    "    return filtered_data\n",
    "\n",
    "# Function to detect and remove outliers using Z-score method\n",
    "def remove_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(data))\n",
    "    filtered_data = data[(z_scores < threshold).all(axis=1)]\n",
    "    return filtered_data\n",
    "\n",
    "def replace_outliers_with_median(data, threshold=1.5):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Calculate lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    # Replace outliers with the median value\n",
    "    median_value = data.median()\n",
    "    data_replaced = data.where(~((data < lower_bound) | (data > upper_bound)), median_value, axis=0)\n",
    "\n",
    "    return data_replaced\n",
    "\n",
    "def replace_outliers_with_median_quantile(data, lower = 0.05, upper=0.95):\n",
    "    # Calculate lower and upper bounds for outliers\n",
    "    lower_bound = data.quantile(lower)\n",
    "    upper_bound = data.quantile(upper)\n",
    "\n",
    "    # Replace outliers with the median value\n",
    "    median_value = data.median()\n",
    "    data_replaced = data.where(~((data < lower_bound) | (data > upper_bound)), median_value, axis=0)\n",
    "\n",
    "    return data_replaced\n",
    "\n",
    "def replace_outliers_with_none_quantile(data, lower = 0.05, upper=0.95):\n",
    "    # Calculate lower and upper bounds for outliers\n",
    "    lower_bound = data.quantile(lower)\n",
    "    upper_bound = data.quantile(upper)\n",
    "\n",
    "    # Replace outliers with the None value\n",
    "    data_replaced = data.where(~((data < lower_bound) | (data > upper_bound)), None, axis=0)\n",
    "\n",
    "    return data_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vif(df):\n",
    "    \n",
    "    df['const'] = 1\n",
    "\n",
    "    # # VIF dataframe\n",
    "    vif_data = pd.DataFrame()\n",
    "    \n",
    "    # calculating VIF for each feature\n",
    "    vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    vif_data['variable'] = df.columns\n",
    "    \n",
    "    return vif_data[vif_data['variable']!='const'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting VIF\n",
    "\n",
    "The output gives us the VIF for each variable. A VIF close to 1 indicates that the variable is not correlated with the other variables, and hence its variance is not inflated at all. A VIF greater than 1 suggests the presence of multicollinearity.\n",
    "\n",
    "As a rule of thumb, a VIF above 5 indicates a high multicollinearity between this variable and the others, and above 10 is very high multicollinearity.\n",
    "\n",
    "A value between 1 and 5 indicates moderate correlation between a given explanatory variable and other explanatory variables in the model, but this is often not severe enough to require attention.\n",
    "\n",
    "A value greater than 5 indicates potentially severe correlation between a given explanatory variable and other explanatory variables in the model. In this case, the coefficient estimates and p-values in the regression output are likely unreliable.\n",
    "\n",
    "\n",
    "| VIF value | Diagnosis                                        |\n",
    "| --------- | ------------------------------------------------ |\n",
    "| 1         | Complete absence of multicollinearity            |\n",
    "| 1-2       | Absence of strong multicollinearity              |\n",
    "| > 2       | Presence of moderate to strong multicollinearity |\n",
    "\n",
    "Note: There is no universal agreement of VIF values for multicollinearity detection. The VIF > 5 or VIF > 10 indicates strong multicollinearity, but VIF < 5 also indicates multicollinearity. It is advisable to have VIF < 2.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
